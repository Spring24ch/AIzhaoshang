{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "137e06e9-006c-47ca-8791-4643b59db6fd",
   "metadata": {},
   "source": [
    "***下载数据集***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b195c089-a7e2-4ed1-ac6e-538501067a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "data_dir = snapshot_download(\n",
    "    repo_id=\"bigcode/the-stack\",\n",
    "    repo_type=\"dataset\",\n",
    "    allow_patterns=\"data/java/*\",\n",
    "    local_dir=\"./the-stack-java\",\n",
    "    token=\"Token\",  # 如果未用 huggingface-cli 登录，需手动传 Token\n",
    ")\n",
    "print(f\"数据已下载到: {data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b4fdb8-d60a-474c-b263-989fd926c3e1",
   "metadata": {},
   "source": [
    "***制作SFT数据集***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b258622-2752-45f9-a300-bb1b846a14fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset, Dataset\n",
    "import random\n",
    "import os\n",
    "\n",
    "def generate_fim_samples(code):\n",
    "    lines = code.split('\\n')\n",
    "    if len(lines) < 10:\n",
    "        return None\n",
    "    start_line = random.randint(3, len(lines)-5)\n",
    "    end_line = min(start_line + random.randint(2, 6), len(lines))  # 补全 2-6 行\n",
    "    return {\n",
    "        \"prefix\": \"\\n\".join(lines[:start_line]),\n",
    "        \"middle\": \"\\n\".join(lines[start_line:end_line]),\n",
    "        \"suffix\": \"\\n\".join(lines[end_line:])\n",
    "    }\n",
    "\n",
    "# 加载数据（非流模式，确保能拆分）\n",
    "dataset = load_dataset(\n",
    "    \"/root/autodl-tmp/fim_dataset/group_2\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "fim_samples = []\n",
    "for sample in dataset:\n",
    "    sample_code = sample[\"content\"]\n",
    "    if len(sample_code) > 10:\n",
    "        fim_sample = generate_fim_samples(sample_code)\n",
    "        if fim_sample:\n",
    "            fim_samples.append(fim_sample)\n",
    "\n",
    "def format_for_llama_factory(s):\n",
    "    return {\n",
    "        \"instruction\": \"Complete the Java code between <|fim_begin|> and <|fim_end|> markers\",\n",
    "        \"input\": f\"<|fim_begin|>{s['prefix']}<|fim_hole|>{s['suffix']}<|fim_end|>\",\n",
    "        \"output\": s['middle']\n",
    "    }\n",
    "\n",
    "formatted_data = [format_for_llama_factory(s) for s in fim_samples]\n",
    "dataset = Dataset.from_list(formatted_data)\n",
    "dataset = dataset.train_test_split(test_size=0.05, seed=42)\n",
    "\n",
    "output_dir = \"/root/autodl-tmp/LLaMA-Factory/data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 显式保存为 JSON（关键步骤）\n",
    "dataset[\"train\"].to_json(f\"{output_dir}/train2.json\")\n",
    "dataset[\"test\"].to_json(f\"{output_dir}/test2.json\")\n",
    "\n",
    "# 配置文件指向正确的 JSON 文件\n",
    "with open(f\"{output_dir}/dataset_info.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"java_fim\": {\n",
    "            \"file_name\": \"train.json\",  # 与实际文件名一致\n",
    "            \"columns\": {\"prompt\": \"input\", \"query\": \"instruction\", \"response\": \"output\"}\n",
    "        }\n",
    "    }, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f644109-9d6d-49f5-9c9d-6bb654809dc6",
   "metadata": {},
   "source": [
    "***制作DPO数据集***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e65d69-e65c-4647-b6a5-6bd72a8c046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 存储构造好的数据集\n",
    "new_dataset = []\n",
    "\n",
    "# JSONL文件路径\n",
    "jsonl_file_path = \"/root/autodl-tmp/LLaMA-Factory/saves/DeepSeek-Coder-6.7B-Base/lora/eval_2025-05-11-11-18-32/generated_predictions.jsonl\"\n",
    "\n",
    "# 逐行读取JSONL文件\n",
    "with open(jsonl_file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        # 构造新的数据结构\n",
    "        new_data = {\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": data[\"prompt\"]\n",
    "                }\n",
    "            ],\n",
    "            \"chosen\": {\n",
    "                \"from\": \"gpt\",\n",
    "                \"value\": data[\"label\"]\n",
    "            },\n",
    "            \"rejected\": {\n",
    "                \"from\": \"gpt\",\n",
    "                \"value\": data[\"predict\"]\n",
    "            }\n",
    "        }\n",
    "        new_dataset.append(new_data)\n",
    "\n",
    "# 输出构造好的数据集，这里只是打印，你也可以将其保存为新的文件\n",
    "# 将构造好的数据集保存为新的JSON文件\n",
    "output_file_path = \"/root/autodl-tmp/LLaMA-Factory/data/dpo_train.json\"\n",
    "with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "    json.dump(new_dataset, output_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5ccf96-7314-4487-a89c-e71bc29bd7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
